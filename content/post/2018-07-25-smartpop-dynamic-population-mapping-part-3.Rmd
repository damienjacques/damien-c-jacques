---
title: Smartpop Dynamic Population Mapping (Part 3)
author: Damien C. Jacques
date: '2018-07-25'
slug: smartpop-dynamic-population-mapping-part-3
categories:
  - R
summary: "This Notebook details the steps of the data analysis carried out for the Smartpop project -- Dynamic Population WP (part 3)."
tags:
  - mobile phone data
  - population
  - R
  - statistics
output:
  blogdown::html_page:
    toc: yes
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      eval = FALSE)
```
### Decompose time series

We use `stl` package to decompose the time series of SIM users into a seasonnal, trend and remainder components. The seasonal component is found by taking the mean of the seasonal sub-series. The seasonal values are removed, and the remainder loess smoothed to find the trend (the span (in lags) of the loess window for trend extraction is `nextodd(ceiling((1.5*period) / (1-(1.5/s.window))))`). The overall level is removed from the seasonal component and added to the trend component. This process is iterated a few times. The remainder component is the residuals from the seasonal plus trend fit.

**Reference**

[R. B. Cleveland, W. S. Cleveland, J.E. McRae, and I. Terpenning (1990) STL: A Seasonal-Trend Decomposition Procedure Based on Loess. Journal of Official Statistics, 6, 3--73.](https://robjhyndman.com/papers/wp13-15.pdf)


```{r, eval = FALSE}
library(data.table)
library(foreach)
library(doMC)

db <- fread("/media/ubuntu/DATA/Data/Smartpop/FinalDB/FinalDB.csv")

registerDoMC(4)
resultdb <- foreach(i = 1:4, .combine = rbind) %dopar% {
                      ID_Grid <- unique(db$ID_Grid)[i]
                      ID.ts <- ts(db$NBR_SIM_BE[db$ID_Grid == ID_Grid], frequency = 24*7)
                      fit <- stl(ID.ts, s.window = "periodic")
                      data.frame(ID_Grid = rep(ID_Grid, 8759),
                                 seasonnal = as.numeric(fit$time.series[,1] + abs(min(fit$time.series[,1]))),
                                 trend = as.numeric(fit$time.series[,2]),
                                 remainder = as.numeric(fit$time.series[,3]),
                                 DATE_HOUR = unique(db$DATE_HOUR))
}

resultdb$DATE_HOUR <- rep(unique(db$DATE_HOUR, 4044))

fwrite(resultdb, "/media/ubuntu/DATA/Data/Smartpop/FinalDB/FinalDB_BE_ts.csv")

```

Build a usable matrix corresponding to the seasonnal component (one week) of Belgium SIM.

```{r, eval = FALSE}
library(data.table)

resultdb <- fread("/media/ubuntu/DATA/Data/Smartpop/FinalDB/FinalDB_BE_ts.csv")

Mat_BE <- dcast(ID_Grid ~  DATE_HOUR, data = resultdb, value.var = "seasonnal")
Mat_BE <- as.matrix(Mat_BE)[, 97:264]
```
```{r, eval = FALSE, echo = FALSE}
save(Mat_BE, file = "/media/ubuntu/DATA/Data/Smartpop/Matrix/Mat_BE_seasonnal.Rda")
```


We also compute a row scaled version (`(x - mean)/std`) of the matrix for further use (clustering...).

```{r}
library(scrime)

Mat_BE_scaled <- rowScales(Mat_BE)
save(Mat_BE_scaled, file = "/media/ubuntu/DATA/Data/Smartpop/Matrix/Mat_BE_seasonnal_scale_center.Rda")
```

```{r, echo = FALSE}
load("/media/ubuntu/DATA/Data/Smartpop/Matrix/Mat_BE_seasonnal.Rda")
load("/media/ubuntu/DATA/Data/Smartpop/Matrix/Mat_BE_seasonnal_scale_center.Rda")
```
### Compute validation dataset for population estimation.

We first compute the population density by statistical sector.

```{r, warning = FALSE, message = FALSE}
library(rgdal)

# shapefile of precomputed population at statistics sector level
shp <- readOGR("/home/ubuntu/Dropbox/Research/Projects/SMARTPOP/Data/Secteur_Stat/shp/pop_sectStat_2015.shp", verbose = FALSE)

# compute population density (> 10 y.)
shp$pop <- rowSums(shp@data[, 26:44])/shp$ar_sqkm

# histogram population density
hist(shp$pop, main = "", xlab = "Population (> 10 y) density (hab/km²)")
```

{{% alert warning %}}
Assumption 5: According to [(GSMA, 2014)](https://www.gsma.com/publicpolicy/wp-content/uploads/2012/03/GSMA_Childrens_use_of_mobile_phones_2014.pdf), only 10% of the population (of 15 years old) have reported ownership of first mobile phone under 10 (2014). Therefore, we only considered the population (> 10 y.)
{{% /alert %}}

![](/img/ownership_mobile_phone.png)

We then rasterize the shapefile for further use (zonal statistics).

```{r, eval = FALSE}
library(raster)

zone <- raster("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.tif")
shp <- spTransform(shp, crs(zone))

writeOGR(shp, "/media/ubuntu/DATA/Data/Smartpop/Population/pop_10_100.shp", 
         layer = "pop_10_100",
         driver = "ESRI Shapefile")

# rasterize shapefile
ext <- "23052 21125 295247 243827"
res <- c("50 50")
attribute <- "pop"
  
path.in <- "/media/ubuntu/DATA/Data/Smartpop/Population/pop_10_100.shp"
path.out <- "/media/ubuntu/DATA/Data/Smartpop/Population/pop_10_100.tif"

command <- 'gdal_rasterize'
command <- paste(command, "--config COMPRESS LZW") 
command <- paste(command, "-a", attribute) 
command <- paste(command, "-te", ext) 
command <- paste(command, "-tr", res) 
command <- paste(command, "-ot Int16")
command <- paste(command, path.in)
command <- paste(command, path.out)
system(command)
```

```{r, message = FALSE, warning = FALSE}
library(raster)
library(rasterVis)
library(classInt)

zone <- raster("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.tif")
pop <- raster("/media/ubuntu/DATA/Data/Smartpop/Population/pop_10_100.tif")
pop[zone == 0] <- NA

levelplot(pop, col.regions = colorRampPalette(brewer.pal(9, 'Blues')),
          margin = FALSE, main = 'Population density (inhab./m²) -- Normal breaks')

breaks <- classIntervals(values(pop), n = 20, style = "quantile")

levelplot(pop, at = c(0, breaks$brks[breaks$brks > 0]), 
          col.regions = colorRampPalette(brewer.pal(9, 'Blues')),
          margin = FALSE, main = 'Population density (inhab./m²) -- Quantile breaks')
```
Average population density in Belgium (> 10 y) is 322.2 inhab./km².

```{r}
sum(as.numeric(values(pop)), na.rm = T)/sum(!is.na(as.numeric(values(pop))))
```

### Dissagreggate population density at voronoi cell
```{r, eval = FALSE}
popVoro <- zonal(pop, zone, mean)
```

```{r, echo = FALSE, eval = FALSE}
popVoro <- zonal(pop, zone, mean)
save(popVoro, file = "/media/ubuntu/DATA/Data/Smartpop/Population/popVoro.Rda")
```

```{r, echo = FALSE}
load("/media/ubuntu/DATA/Data/Smartpop/Population/popVoro.Rda")
```

```{r, warning = FALSE, message = FALSE}
zone <- raster("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.tif")
popZone <- reclassify(zone, popVoro)

breaks <- classIntervals(values(popZone), n = 20, style = "quantile")

levelplot(popZone, at = c(0, breaks$brks[breaks$brks > 0]), 
          col.regions = colorRampPalette(brewer.pal(9, 'Blues')),
          margin = FALSE, main = 'Population density (inhab./m²) -- Quantile breaks')
```

## Population modeling using SIM users


We first need to define training and testing dataset.

```{r}
library(raster)

zone <- readOGR()
<- centroid()

pointDistance
```


### Population model with OLS regression (simple linear regression)

```{r, warning = FALSE, message = FALSE}
library(rgdal)
library(Metrics)
library(data.table)

zoneShp <- readOGR("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.shp", verbose = FALSE)

df <- data.frame(i = 1:168, 
                 r = 1:168,
                 r2 = 1:168,
                 rmse = 1:168)


for (i in 1:168) {
  y <- as.numeric(popVoro[-1,2])
  x <- as.numeric(Mat_BE[,i]/zoneShp$area)
  
  index <- which(x == 0 | y == 0)
  y <- y[-index]
  x <- x[-index]

  data <- data.frame(x = x, y = y)
  lm.model <- lm(y ~ x, data = data) 
  lm.model <- lm(y ~ poly(x,10), data = data)

  df$r2[i] <- summary(lm.model)$r.squared
  df$r[i] <- cor(y, predict(lm.model, newdata = data))
  df$rmse[i] <- rmse(y, predict(lm.model, newdata = data))
  # df$coef[i] <- lm.model$coefficients
}

plot(df$i, df$r, type = "o", ylab = "pearson correlation", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$rmse, type = "o", ylab = "RMSE (inhab./km²)", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$r2, type = "o", ylab = "r² (of log-log model, not really relevant)", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 
```

### Population model with OLS regression (linear regression with log-log transformation)

The issue is how to deal with the 0. We choose to ignore them.

```{r, warning = FALSE, message = FALSE}
library(rgdal)
library(Metrics)
library(data.table)

zoneShp <- readOGR("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.shp", verbose = FALSE)

df <- data.frame(i = 1:168, 
                 r = 1:168,
                 r2 = 1:168,
                 rmse = 1:168)

for (i in 1:168) {
  y <- as.numeric(log(popVoro[-1,2])) 
  x <- as.numeric(log((Mat_BE[,i])/zoneShp$area))
  index <- which(x == -Inf | y == -Inf)
  y <- y[-index]
  x <- x[-index]

  lm.model <- lm(y ~ x) 
  
  df$r2[i] <- summary(lm.model)$r.squared
  df$r[i] <- cor(exp(y), exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))
  df$rmse[i] <- rmse(exp(y), exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))
  # df$coef[i] <- lm.model$coefficients
}

plot(df$i, df$r, type = "o", ylab = "pearson correlation", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$rmse, type = "o", ylab = "RMSE (inhab./km²)", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$r2, type = "o", ylab = "r² (of log-log model, not really relevant)", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 
```

Regarding correlation, we observe:

* in average, a decrease in correlation along the week (monday to saturday), then an increase sunday.
* the lowest correlation at 4 am (from monday to wednesday)
* the highest during late evening (11-12pm during week days)
* a plateau in correlation from 5 am to 5pm (during week days)

Regarding RMSE, we observe:

* in average, an increase in RMSE along the week (monday to saturday), then an increase sunday.
* the highest correlation at 4 am (week days)
* higher RMSE in working hours
* very high RMSE friday night


### Population model with OLS weighted regression (Deville PNAS paper)

Weighted regression are used to reduce heteroscedasticity However, if the heteroscedasticity comes from an omitted variable, this approach could be wrong.

> Keep in mind that there are different reasons why residuals can have non-constant variance. We tackled one that involved a predictor variable that had a large range of values and was associated with the changing variance. Other reasons for heteroscedasticity can include an incorrect model, such as a missing predictor. Weighted regression is not an appropriate solution if the heteroskedasticity is caused by an omitted variable. So, you really have to use your subject-area knowledge to first determine what is causing the problem and then figure out how to fix it!

From [here](http://blog.minitab.com/blog/adventures-in-statistics-2/curing-heteroscedasticity-with-weighted-regression-in-minitab-statistical-software).


```{r, warning = FALSE, message = FALSE}
library(rgdal)
library(Metrics)

zoneShp <- readOGR("/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.shp", verbose = FALSE)
load("/media/ubuntu/DATA/Data/Smartpop/Matrix/Mat_BE_seasonnal_scale_center.Rda")

df <- data.frame(i = 1:168, 
                 r = 1:168,
                 r2 = 1:168,
                 rmse = 1:168)

y <- as.numeric(log(popVoro[-1,2])) 
y[y == -Inf] <- 0

for (i in 1:168) {
  x <- as.numeric(log((Mat_BE[,i] + abs(min(Mat_BE)) + 0.1) / zoneShp$area))
  x[x == -Inf] <- 0

  # log-log population weighted regression (weight used to prevent heteroscedasticity)
  lm.model <- lm(y ~ x, w = popVoro[-1,2] * zoneShp$area) 
  
  df$r2[i] <- summary(lm.model)$r.squared
  df$r[i] <- cor(popVoro[-1,2], exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))
  df$rmse[i] <- rmse(popVoro[-1,2], exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))
}

plot(df$i, df$r, type = "o", ylab = "pearson correlation", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$rmse, type = "o", ylab = "RMSE (inhab./km²)", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 

plot(df$i, df$r2, type = "o", ylab = "r²", xlab = "time", xaxt = "n", pch = 20) +
axis(1, at = seq(13, 168, 24), labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
abline(v = seq(1, 168, 24)) 
```
Compare to unweighted regression, we observe:

* similar correlation lines.
* higher RMSE


### Residual analysis


```{r}
i = 24

y <- as.numeric(log(popVoro[-1,2])) 
y[y == -Inf] <- 0

x <- as.numeric(log((Mat_BE[,i] + abs(min(Mat_BE)) + 0.1) / zoneShp$area))
x[x == -Inf] <- 0

lm.model <- lm(y ~ x) 

residuals <- popVoro[-1,2] - exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x)

cor(abs(residuals), zoneShp$area)
cor(abs(residuals), popVoro[-1,2])

plot(zoneShp$area, popVoro[-1,2])
plot(popVoro[-1,2], abs(residuals)/popVoro[-1,2], ylim=c(0,4))
plot(popVoro[-1,2], abs(residuals), ylim=c(0,20000))

```
We observe higher residuals (positive and negative) in urban areas. 


```{r}
library(raster)
library(rasterVis)
library(classInt)

# Residuals

zoneShp$residuals <- residuals

my.palette <- brewer.pal(n = 5, name = "Spectral")

breaks <- classIntervals(residuals, n = 5, style = "quantile")

spplot(zoneShp, "residuals", at = breaks$brk,
       col.regions = my.palette, col = "transparent", cuts = 8,  usePolypath = FALSE,
       main = "residuals")

# writeOGR(zoneShp, "/media/ubuntu/DATA/Data/Smartpop/Residuals/residuals.shp",
#          layer = "residuals", driver = "ESRI Shapefile")

# Absolute residuals

zoneShp$residuals <- abs(residuals)

my.palette <- brewer.pal(n = 9, name = "Blues")

breaks <- classIntervals(abs(residuals), n = 9, style = "quantile")

spplot(zoneShp, "residuals", at = breaks$brk,
       col.regions = my.palette, col = "transparent", cuts = 8,  usePolypath = FALSE,
       main = "absolute residuals")
```

Dynamic exploration with leaflet.

```{r}
library(leaflet)
library(widgetframe)

zoneShp_latlon <- spTransform(zoneShp, CRS("+init=epsg:4326"))

zoneShp_latlon$cl <- as.numeric(cut(residuals, breaks = 9))
zoneShp_latlon$cl2 <- as.numeric(cut(residuals, 
                                     breaks = c(quantile(residuals, probs = seq(0, 1, by = 1/9))),
                                 include.lowest = T))

colors <- brewer.pal(n = 9, name = "Spectral")


l <- leaflet() %>%
  setView(lng = 5.578661, lat = 50.633766,, zoom = 12) %>%
  # Base groups
  addProviderTiles(providers$Stamen.Toner, group = "Toner") %>%
  addTiles(group = "OSM (default)") %>%
  addProviderTiles(providers$Esri.WorldImagery, group = "ESRI World Imagery") %>%
  # Overlay groups
  addPolygons(data = zoneShp_latlon, color = ~colors[cl], fillOpacity = 0.9, 
              layerId = ~ID, popup = ~ID,
              highlightOptions = highlightOptions(color = "black", 
                                                  weight = 2
                                                  ),
               group = "equal interval") %>%
  addPolygons(data = zoneShp_latlon, color = ~colors[cl2], fillOpacity = 0.9, 
              layerId = ~ID, popup = ~ID,
              highlightOptions = highlightOptions(color = "black", 
                                                  weight = 2),
               group = c("quantile")) %>%
  # Legends
  addLegend("bottomleft", colors = colors, labels = levels(cut(residuals, breaks = 9)),
    title = "Residuals", opacity = 1, group = c("quantile")) %>%
    addLegend("bottomleft", colors = colors, labels = levels(cut(residuals, 
                                     breaks = c(quantile(residuals, probs = seq(0, 1, by = 1/9))))),
    title = "Residuals", opacity = 1, group = c("equal interval")) %>%
  # Layers control
  addLayersControl(
        baseGroups = c("Toner", "OSM (default)", "ESRI World Imagery"),
    overlayGroups = c("equal interval", "quantile", "hide"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>% 
  hideGroup("equal interval")

frameWidget(l)



library(shiny)
# make a copy of Mobile_Phone_ByDay
Mobile_Phone_ByDay_comp <- Mobile_Phone_ByDay
# Store all date (using an antenna active the 365 days)
dates <- lubridate::ymd(Mobile_Phone_ByDay$`substr(DATE_HOUR, 1, 10)`[Mobile_Phone_ByDay$ID==1211])


server <- function(input, output) {
  # Leaflet map with markers
  output$map <- renderLeaflet({
    leaflet() %>%
      setView(lng = 5.578661, lat = 50.633766, zoom = 12) %>%
      addProviderTiles(providers$Stamen.Toner, group = "Toner") %>%
      addCircleMarkers(data = antenna_select_latlon, ~lon, ~lat, layerId= ~ID, popup = ~ID, radius = 4,
                       color="blue", fillOpacity = 0.9,  stroke = TRUE) %>%
      addCircleMarkers(data = antenna_discard_latlon, ~lon, ~lat, layerId= ~ID, popup = ~ID, radius = 4,
                       color="red", fillOpacity = 0.9,  stroke = TRUE)
  })
  
  # Generate data in reactive for time series 1
  plot_data <- reactive({
    ID <- input$map_marker_click$id
    if(is.null(ID)){ID=800}
    Mobile_Phone_ByDay[Mobile_Phone_ByDay$ID %in% ID,]
  })
  
  # Generate data in reactive for time series 2
  plot_data_comp <- reactive({
    ID_comp <- input$location
    
    if(is.null(ID_comp)){ID_comp = 800}
    Mobile_Phone_ByDay_comp[Mobile_Phone_ByDay_comp$ID %in% ID_comp,]
  })
  
  # Zoom on selected antenna using the drop-down menu
  observeEvent(input$location, {
    p2 <- antenna_discard_latlon[antenna_discard_latlon$ID == input$location,]
    leafletProxy("map") %>% 
      setView(lng=p2$lon, lat=p2$lat, zoom=14) %>% 
      addCircleMarkers(p2$lon, p2$lat, radius=8, color="black", 
                       fillColor="red", fillOpacity=1, opacity=1, 
                       stroke=TRUE, layerId="Selected")
    
  })
  
  # Make a plot depending on the selected antennas
  output$plot=renderPlot({
    plot(dates, rep(NA, 365), ylim = c(0, 15000), ylab = "N SIM BE")
    lines(lubridate::ymd(plot_data_comp()$`substr(DATE_HOUR, 1, 10)`),  
          plot_data_comp()$SIM_BE, 
          col = "red")
    lines(lubridate::ymd(plot_data()$`substr(DATE_HOUR, 1, 10)`),
          plot_data()$SIM_BE, 
          col ="black")
    legend("topright", col = c("red", "black"), lty = 1,
           c("active < 365 days", "active <= 365 days"),
           bty = "n")
  })
  
  # Generate text with the number of active days for the antenna selected with the drop-down menu
  output$n_days <- renderText({ 
    paste("N active days:", frequencyAntenna[which(names(frequencyAntenna) == input$location)])
  })
}

# Make user interface
ui <- fluidPage(
  br(),
  fluidRow(
    column(4, h2("Explore Antennas (SMARTPOP)"), h3("Click on antenna for comparison (black line)")),
    column(4, selectInput("location", "Antenna active < 365 days (red line)", 
                          c("", as.character(antenna_discard_latlon$ID)), 
                          selected="", multiple=F, width="100%")),
    column(4, textOutput("n_days"))
  ),
  fluidRow(
    column(4, leafletOutput("map")),
    column(8, plotOutput("plot"))
  ),
  br()
)

# Launch the app
shinyApp(ui = ui, server = server)
```



```{r}
cl <- kmeans(Mat_BE, 10) #already scaled
cl <- cl$cluster

df <- data.frame(residuals = residuals, cl = cl)
df <- data.frame(residuals = residuals, cl = cut(residuals, breaks = 10))
df <- data.frame(residuals = residuals, cl = cut(residuals, 
                                                 breaks = c(quantile(residuals, probs = seq(0, 1, by = 0.1)))))

boxplot(residuals ~ cl, df)

library(lme4)

lmer.model <- lmer(y ~ x + (1 + x | cl), data = df)
summary(lmer.model)
plot(exp(y), exp(predict(lmer.model, newdata = df)))
cor(exp(y), exp(predict(lmer.model, newdata = df)))

lm.model <- lm(y ~ x, data = df)
summary(lm.model)
plot(y, predict(lm.model, newdata = df))
```









```{r}
my.palette <- brewer.pal(n = 5, name = "Spectral")

colors <- my.palette[as.numeric(cut(residuals, breaks = 5))]
colors <- my.palette[as.numeric(cut(residuals, breaks=c(quantile(residuals, probs = seq(0, 1, by = 0.1))), include.lowest=TRUE))]
plot(exp(x), exp(y), pch = 20, col = colors)

plot((x), (y), pch = 20, col = colors)
```

  



















```{r, eval = FALSE, echo = FALSE}
library(raster)
i= 22
x <- as.numeric(log((Mat_BE[,i] + abs(min(Mat_BE)) + 0.1) / zoneShp$area))
x[x == -Inf] <- 0

# log-log population weighted regression
lm.model <- lm(y ~ x, w = zoneShp$area*exp(y)) 
df$r2[i] <- summary(lm.model)$r.squared
df$r[i] <- cor(exp(y), exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))
df$rmse[i] <- rmse(exp(y), exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x))


df.plot <- cbind.data.frame(exp(lm.model$coefficients[1] + lm.model$coefficients[2]*x), popVoro[-1,2])
colnames(df.plot) <- c("x", "y")

library(ggplot2)
library(viridis)

ggplot(df.plot, aes(x, y)) +
  stat_density_2d(aes(fill = ..density..), geom = 'raster', contour = FALSE) +       
  scale_fill_viridis(option="magma") +
  coord_cartesian(expand = FALSE) +
  geom_point( col = 'white') +
  ylim(c(0,30000))

```

```{r}
# Rasterize Shapefile
path.in <- "/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.shp"
path.out <- "/media/ubuntu/DATA/Data/Smartpop/Zone/zone_50m.tif"
ext <- "23052 21125 295247 243827"
res <- c("50 50")
attribute <- 'ID'

command <- 'gdal_rasterize'
command <- paste(command, "--config COMPRESS LZW") 
command <- paste(command, "-a", attribute) 
command <- paste(command, "-te", ext) 
command <- paste(command, "-tr", res) 
command <- paste(command, "-ot Int16")
command <- paste(command, path.in)
command <- paste(command, path.out)
```


```{r}

Mat_BE_scale <- t(scale(t(Mat_BE)))
cl <- kmeans(Mat_BE, 10)
cl <- cl$cluster

save(cl, file = "/media/ubuntu/DATA/Data/Smartpop/Clustering/cl.Rda")

for (i in 1:10) {
  cl1 <- colMeans(Mat_BE[which(cl$cluster == i), ])
  plot(cl1, type = "l", ylim = c(-1,1))
  abline(v = seq(1, 24*7, 24))
  abline(v = seq(13, 24*7, 24), lty = 2)
}

plot()
plot(Mat_BE[which(cl$cluster == 8), ][1,])

```

```{r}
PC <- prcomp(Mat_BE)
```

```{r}
for (ID_Grid in unique(db$ID_Grid)) {
  print(ID_Grid)
  ID.ts <- ts(db$NBR_SIM_BE[db$ID_Grid == ID_Grid], frequency = 24*7)
  fit <- stl(ID.ts, s.window = "periodic")
  db$seasonnal[db$ID_Grid == ID_Grid] <- fit$time.series[,1] + abs(min(fit$time.series[,1]))
  db$trend[db$ID_Grid == ID_Grid] <- fit$time.series[,2]
  db$remainder[db$ID_Grid == ID_Grid] <- fit$time.series[,3]
}


db$seasonnal <- NA
db$trend <- NA
db$remainder <- NA

fwrite(db, "/media/ubuntu/DATA/Data/Smartpop/FinalDB/FinalDB_BE_ts.csv")

```
```{r}

head(db)

Mat_BE <- xtabs(NBR_SIM_BE ~ DATE_HOUR + ID_Grid, data = db)


```

